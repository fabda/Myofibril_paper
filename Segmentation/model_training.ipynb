{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET-seResNet18 segmentation network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a segmentation model on T0 dataset from sratch.\n",
    "\n",
    "Feel free to change the *path_images* and *path_masks* parameters to process another dataset into the cell below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T0 dataset\n",
    "path_images = \"data/T0/images/\"\n",
    "path_masks  = \"data/T0/masks/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_directory(folder,resize,filextension):\n",
    "    '''\n",
    "    This function read images from a directory and store it into a Numpy array\n",
    "    \n",
    "    folder : path to the folder containing the images\n",
    "    resize : target size of the images stored into the Numpy array\n",
    "    filextension: image format. For the moment only 'tif' images are accepted\n",
    "    \n",
    "    Use : X = load_images_from_directory( foo/bar/, (128,128), 'tif')\n",
    "    \n",
    "    '''\n",
    "    images  = []\n",
    "    img_rows=resize[0]\n",
    "    img_cols=resize[1]\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        curimg = os.path.join(folder, filename)\n",
    "        if curimg.endswith(filextension):\n",
    "            img = Image.open(curimg)\n",
    "            resize = img.resize((img_rows,img_cols), Image.NEAREST)\n",
    "            images.append(resize)\n",
    "    imgarray=list();\n",
    "    for i in range(len(images)):\n",
    "        tmp = np.array(images[i])\n",
    "        imgarray.append(tmp)\n",
    "    imgarray = np.asarray(imgarray).astype('float32')\n",
    "\n",
    "    if len(imgarray.shape)==3:\n",
    "        imgarray = np.expand_dims(imgarray,axis=3)\n",
    "\n",
    "    return imgarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size=(128,128)\n",
    "\n",
    "BACKBONE = \"seresnet18\"\n",
    "\n",
    "bs = 32\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "steps_per_epoch = 400\n",
    "\n",
    "validation_steps = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read, prepare and Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and masks\n",
    "\n",
    "X = load_images_from_directory(path_images,target_size,'tif')\n",
    "y = load_images_from_directory(path_masks,target_size,'tif')\n",
    "\n",
    "print (X.shape[0], \": total images read from directory\")\n",
    "print (y.shape[0], \": total masks  read from directory\")\n",
    "\n",
    "\n",
    "#Preprocess images and masks\n",
    "\n",
    "X = np.concatenate((X,X,X),axis=3)\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "X = preprocess_input(X)\n",
    "\n",
    "y = y/255\n",
    "\n",
    "#Split\n",
    "\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.1)\n",
    "\n",
    "print(X_train.shape[0], \" : training images\")\n",
    "print(X_valid.shape[0], \" : validation images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    fill_mode = \"reflect\",\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    zoom_range=0.2\n",
    "    \n",
    ")\n",
    "\n",
    "it = datagen.flow(X_train, batch_size=bs,seed=1)\n",
    "it2 = datagen.flow(y_train, batch_size=bs,seed=1)\n",
    "\n",
    "train_generator = zip(it,it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that augmentation is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We display one image for a random generated batch of images from the augmentation generator\n",
    "a,b = next(train_generator)\n",
    "\n",
    "#one image\n",
    "plt.imshow(a[0,:,:,0],cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "#correspinding mask\n",
    "plt.imshow(b[0,:,:,0]>0.5,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained UNET-seResNet18 creation from _segmentation model_ [library](https://github.com/qubvel/segmentation_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet', input_shape=X.shape[1:],classes=1, activation='sigmoid')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss (Dice loss) and Metrics (Intersection Over Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    Adam(lr=lr),\n",
    "    loss=sm.losses.dice_loss,\n",
    "    metrics=[sm.metrics.iou_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = model.fit_generator(\n",
    "    train_generator,\n",
    "    validation_data  = (X_valid,y_valid),\n",
    "    epochs           = epochs,\n",
    "    steps_per_epoch  = steps_per_epoch,\n",
    "    validation_steps = validation_steps,\n",
    "    verbose          = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and check the segmentation quality on a random image from the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = 1\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.squeeze((p[img])>0.5),cmap=\"gray\")\n",
    "#plt.imshow(np.squeeze(p[img]<0.5),cmap=\"gray\")\n",
    "#plt.imshow(np.squeeze(p[img]<0.5),cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.squeeze(y_valid[img]),cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.squeeze(X_valid[img][:,:,0]),cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/T0/jerome_128x128_seresnet18_e20_spe400.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.15-keras2.2.4",
   "language": "python",
   "name": "tf1.15-keras2.2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
